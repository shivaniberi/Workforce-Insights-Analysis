[2024-12-05T23:21:30.797+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-12-05T23:21:30.819+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: job_listings_etl_v2.load_csv manual__2024-12-05T23:21:08.591495+00:00 [queued]>
[2024-12-05T23:21:30.824+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: job_listings_etl_v2.load_csv manual__2024-12-05T23:21:08.591495+00:00 [queued]>
[2024-12-05T23:21:30.825+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 4
[2024-12-05T23:21:30.835+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_csv> on 2024-12-05 23:21:08.591495+00:00
[2024-12-05T23:21:30.850+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=969) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-12-05T23:21:30.853+0000] {standard_task_runner.py:63} INFO - Started process 972 to run task
[2024-12-05T23:21:30.853+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'job_listings_etl_v2', 'load_csv', 'manual__2024-12-05T23:21:08.591495+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/ETL_FINAL_PROJECT (1).py', '--cfg-path', '/tmp/tmpimbodk64']
[2024-12-05T23:21:30.855+0000] {standard_task_runner.py:91} INFO - Job 44: Subtask load_csv
[2024-12-05T23:21:30.928+0000] {task_command.py:426} INFO - Running <TaskInstance: job_listings_etl_v2.load_csv manual__2024-12-05T23:21:08.591495+00:00 [running]> on host 1ed1f547130e
[2024-12-05T23:21:31.093+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='job_listings_etl_v2' AIRFLOW_CTX_TASK_ID='load_csv' AIRFLOW_CTX_EXECUTION_DATE='2024-12-05T23:21:08.591495+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-05T23:21:08.591495+00:00'
[2024-12-05T23:21:31.096+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-12-05T23:21:31.112+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-12-05T23:21:31.115+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-5.10.25-linuxkit-aarch64-with-glibc2.36
[2024-12-05T23:21:31.117+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-12-05T23:21:32.467+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-12-05T23:21:35.104+0000] {ETL_FINAL_PROJECT (1).py:238} ERROR - Error loading data into DEV.RAW_DATA.HISTORICAL_DATA: 100072 (22000): None: NULL result in a non-nullable column
[2024-12-05T23:21:35.110+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-12-05T23:21:35.137+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/ETL_FINAL_PROJECT (1).py", line 231, in load_csv
    cur.executemany(insert_query, [
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1437, in executemany
    self.execute(command, params=param, _do_reset=False, **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.IntegrityError: 100072 (22000): None: NULL result in a non-nullable column

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/ETL_FINAL_PROJECT (1).py", line 239, in load_csv
    raise AirflowException(f"Failed to load data into {target_table}: {e}")
airflow.exceptions.AirflowException: Failed to load data into DEV.RAW_DATA.HISTORICAL_DATA: 100072 (22000): None: NULL result in a non-nullable column
[2024-12-05T23:21:35.148+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=job_listings_etl_v2, task_id=load_csv, run_id=manual__2024-12-05T23:21:08.591495+00:00, execution_date=20241205T232108, start_date=20241205T232130, end_date=20241205T232135
[2024-12-05T23:21:35.170+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 44 for task load_csv (Failed to load data into DEV.RAW_DATA.HISTORICAL_DATA: 100072 (22000): None: NULL result in a non-nullable column; 972)
[2024-12-05T23:21:35.259+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-12-05T23:21:35.306+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-12-05T23:21:35.308+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
